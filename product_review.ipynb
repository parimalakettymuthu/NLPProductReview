{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "787921f8-dbe9-4d5a-9025-b91194f3e0f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reviews = spark.sql(\"SELECT * FROM reviews_2\")\n",
    "reviews.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a82263af-633f-4966-a831-98c9835e7022",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reviews.select(\"Text\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0a6d00-3f35-44b0-80bb-ffe4fa52c371",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reviews.select(\"Text\").first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97c91429-8577-4b38-8953-c6b222cc6f51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "score_counts = reviews.groupBy(\"Score\").count().orderBy(\"Score\").toPandas()\n",
    "\n",
    "score_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07bf4001-89b3-4518-ae9a-65cf5777a413",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(score_counts[\"Score\"], score_counts[\"count\"], color=\"skyblue\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Review Count\")\n",
    "plt.title(\"Review Count Based on Score\")\n",
    "#plt.xticks(score_counts[\"Score\"])\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0fed81-13f5-443d-b836-4807ee5b84a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "reviews = reviews.withColumn(\"ReviewSentiment\", when(reviews[\"Score\"] <=3, \"Negative Review\").otherwise(\"Positive Review\"))\n",
    "reviews.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a6448c8-f5c2-415f-935a-24e5740240e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "review_count = reviews.groupBy(\"ReviewSentiment\").count().orderBy(\"ReviewSentiment\").toPandas()\n",
    "review_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82fcf64d-5ce6-4df3-b5c4-b481d731c2a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(review_count[\"ReviewSentiment\"], review_count[\"count\"], color=\"skyblue\")\n",
    "plt.xlabel(\"ReviewSentiment\")\n",
    "plt.ylabel(\"Review Count\")\n",
    "plt.title(\"Review Count Based on Score\")\n",
    "#plt.xticks(score_counts[\"Score\"])\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c8ba2a-8526-4fbd-aa98-e03350e4f936",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567a7c11-1f9e-429b-b4d4-3ab6d6fd4a84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    #Convert to lowercase \n",
    "    text = text.lower()\n",
    "    #Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    #Tokenization \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #Stopword removal\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    #Stemming\n",
    "    lemmatize = WordNetLemmatizer()\n",
    "    tokens = [lemmatize.lemmatize(word) for word in tokens]\n",
    "    #join tokens back into text\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40119a4c-b670-4eeb-9f85-ba87e109fe7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "#Register preprocessing function as udf \n",
    "preprocess_udf = udf(preprocess_text, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70898dea-05e8-4771-98da-7d008cc5abad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Apply pre\n",
    "\n",
    "#Apply preprocessing to each review\n",
    "preprocessed_reviews = [preprocess_text(reviews) for review in reviews[\"Text\"]]\n",
    "\n",
    "#Vectorization using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit.transform(preprocessed_reviews)\n",
    "y = reviews.ReviewSentiment\n",
    "#Splitting data into training & test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Display preprocessed reviews\n",
    "print(\"Preprocessed reviews: \")\n",
    "for review in preprocessed_reviews:\n",
    "    print(review)\n",
    "\n",
    "#Display TF-IDF vectors\n",
    "print(\"\\n TF-IDF vectors:\")\n",
    "print(X.toarray())\n",
    "\n",
    "#Display training and test data shapes\n",
    "print(\"\\nTraining Data Shape: \", X_train.shape)\n",
    "print(\"\\nTest Data Shape: \", X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 311249187624342,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "product_review",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
